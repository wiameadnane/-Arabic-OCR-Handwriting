{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "305149af-6057-4012-b049-bd9d82e482f3",
   "metadata": {},
   "source": [
    "# PROJECT : ARABIC OCR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b037ff7-6e53-4841-b717-47ecd7489f2a",
   "metadata": {
    "id": "3b037ff7-6e53-4841-b717-47ecd7489f2a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-16 00:46:43.790283: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-16 00:46:43.824892: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750031203.849169    5992 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750031203.856003    5992 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1750031203.881178    5992 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750031203.881204    5992 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750031203.881205    5992 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750031203.881206    5992 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-16 00:46:43.887016: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"\n",
    "\n",
    "import tensorflow as tf\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1811c915-6de2-4b3e-872d-a8f5a93bd83b",
   "metadata": {
    "id": "1811c915-6de2-4b3e-872d-a8f5a93bd83b"
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70974c67-b959-484b-b15a-f4aab6612929",
   "metadata": {
    "id": "70974c67-b959-484b-b15a-f4aab6612929"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from numpy.random import RandomState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afef2ea1-b7bd-4bdf-9b0b-12c06695665c",
   "metadata": {
    "id": "afef2ea1-b7bd-4bdf-9b0b-12c06695665c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv2D, BatchNormalization, ReLU, Dropout, MaxPooling2D,\n",
    "    DepthwiseConv2D, ZeroPadding2D, Reshape, Dense, Bidirectional,\n",
    "    LSTM, Lambda\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34aef9a-9957-47a7-84b7-05110d5e18f0",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3094d30-237d-4d47-a363-7d77b5da60ef",
   "metadata": {
    "id": "c3094d30-237d-4d47-a363-7d77b5da60ef"
   },
   "outputs": [],
   "source": [
    "#fonction qui prend en parametre le path du tru et renvoi les labels\n",
    "def extract_lbl_chars(tru_file_path):\n",
    "    try:\n",
    "        with open(tru_file_path, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "            lines = f.read().splitlines()\n",
    "            if len(lines) < 7:\n",
    "                return None\n",
    "            label_line = lines[6]\n",
    "            match = re.search(r\"AW2:(.*?);\", label_line)\n",
    "            if match:\n",
    "                return match.group(1).split('|')[:-1]\n",
    "            else:\n",
    "                return None\n",
    "    except Exception as e:\n",
    "        print(f\"[ERREUR] Fichier .tru non lisible ou manquant : {tru_file_path}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b827abc0-b903-48e7-b4ea-91efe481aa62",
   "metadata": {
    "id": "b827abc0-b903-48e7-b4ea-91efe481aa62"
   },
   "outputs": [],
   "source": [
    "#creer un dictionnaire ou les cles c'est les noms des images et les valeurs c'est la liste des labels , utilise extract_lbl_chars\n",
    "def walk_and_extract_lbl_gt(root_dir):   #prend en parametre par exemple set a    #useless\n",
    "    labels = {}\n",
    "    for subdir, _, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.tru'):\n",
    "                tru_file_path = os.path.join(subdir, file)\n",
    "                chars = extract_lbl_chars(tru_file_path)\n",
    "                if chars is not None:\n",
    "                    labels[file.split('.')[0]] = chars\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c8c59fb-dbca-40af-8d22-287c59b9195e",
   "metadata": {
    "id": "0c8c59fb-dbca-40af-8d22-287c59b9195e"
   },
   "outputs": [],
   "source": [
    "#fonction qui supprime les mots avec chadda et avec des erreurs, utilise extract_lbl_chars\n",
    "def evaluate_data(root_dir_data, root_dir_tru):\n",
    "    for subdir, _, files in os.walk(root_dir_data):\n",
    "        for file in files:\n",
    "            basename = file.split('.')[0]\n",
    "            word_file_path = f\"{root_dir_data}/{basename}.tif\"\n",
    "            tru_file_path = f\"{root_dir_tru}/{basename}.tru\"\n",
    "            chars = extract_lbl_chars(tru_file_path)\n",
    "            for c in chars:\n",
    "                if c[-1] in ('1', '2') or c.find(\"llL\")!=-1:\n",
    "                    os.remove(word_file_path)\n",
    "                    os.remove(tru_file_path)\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c599e4d9-4b96-4434-b57b-1ed6f6f0041e",
   "metadata": {
    "id": "c599e4d9-4b96-4434-b57b-1ed6f6f0041e"
   },
   "outputs": [],
   "source": [
    "#fonction qui prend chemin et retourne le nom seul\n",
    "def get_basename(name):\n",
    "    return os.path.split(name)[1].split('.')[0] #split divise le chemin en deux partie : le repertoire et le nom de l'image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a10d10e-7dbd-4e5e-9e42-9006b9d8c74c",
   "metadata": {
    "id": "6a10d10e-7dbd-4e5e-9e42-9006b9d8c74c"
   },
   "outputs": [],
   "source": [
    "#fonction qui prend chemin est extrait label\n",
    "def get_word(path_img):\n",
    "    word_name = get_basename(path_img)\n",
    "    path_parts = path_img.split('/')\n",
    "    tru_path = '/'.join(path_parts[:-2]) + '/tru'\n",
    "    tru_file_path = tru_path+\"/\"+word_name+\".tru\"\n",
    "\n",
    "    return extract_lbl_chars(tru_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4aba2835-43e4-499a-8d1d-62573011ba5a",
   "metadata": {
    "id": "4aba2835-43e4-499a-8d1d-62573011ba5a"
   },
   "outputs": [],
   "source": [
    "#fonction qui nous donne le lexique du dataset\n",
    "def get_lexicon(names):\n",
    "    chars = []\n",
    "    for name in names:\n",
    "        chars += get_word(name)\n",
    "    lexicon = list(set(chars))\n",
    "    lexicon.append(\"-\")\n",
    "    return lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22553233-84f1-48a8-b672-9c775755cc23",
   "metadata": {
    "id": "22553233-84f1-48a8-b672-9c775755cc23"
   },
   "outputs": [],
   "source": [
    "#fonction qui calcule length of word based on image link\n",
    "def get_lengths(names):\n",
    "    result = {}\n",
    "    for name in names:\n",
    "        word = get_word(name)\n",
    "        if word is not None and len(word) > 0:\n",
    "            result[get_basename(name)] = len(word)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03716e1f-5e22-4a8b-af42-71ef5d608b38",
   "metadata": {
    "id": "03716e1f-5e22-4a8b-af42-71ef5d608b38"
   },
   "outputs": [],
   "source": [
    "#fonction qui prend le nom de l'image et la pretraite, utilisé dans generator\n",
    "def get_image(name, img_size=(100, 300)):\n",
    "    img = cv2.imread(name, 0)\n",
    "    img = cv2.resize(img, (img_size[1], img_size[0]), Image.LANCZOS)\n",
    "    img = cv2.threshold(img, 255//2, 255, cv2.THRESH_BINARY)[1]\n",
    "    img = cv2.bitwise_not(img)    #inverser limage pour avoir liformation dans le blanc (le texte)\n",
    "    word = get_word(name)\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    return img, word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34d41d35-bcff-45f6-8792-2d65974a4ff2",
   "metadata": {
    "id": "34d41d35-bcff-45f6-8792-2d65974a4ff2"
   },
   "outputs": [],
   "source": [
    "dataset_sets = ['/mnt/c/Users/abder/Documents/S8/DeepLearning/data_augmented/' + set_name for set_name in ('set_a', 'set_b', 'set_c')]\n",
    "data_paths = [set_path + '/tif' for set_path in dataset_sets]\n",
    "tru_paths = [set_path + '/tru' for set_path in dataset_sets]\n",
    "\n",
    "# for data_path, tru_path in zip(data_paths, tru_paths):\n",
    "#     evaluate_data(data_path, tru_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc014127-ea3d-4527-a0ab-1370a675dd91",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cc014127-ea3d-4527-a0ab-1370a675dd91",
    "outputId": "bac16b5f-4ac0-42da-c2b6-9c0ad1897e02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25887\n"
     ]
    }
   ],
   "source": [
    "names = []\n",
    "for data_path in data_paths:\n",
    "    names += [dp+\"/\"+f for dp, _, filenames in os.walk(data_path) for f in filenames if re.search('.tif', f)]\n",
    "names.sort()\n",
    "print(len(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af42a8c5-5bf0-4712-a08e-a2315d82f781",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "af42a8c5-5bf0-4712-a08e-a2315d82f781",
    "outputId": "5eed44b9-0cf5-44af-dac8-2b5622395729"
   },
   "outputs": [],
   "source": [
    "# lexicon = get_lexicon(names)\n",
    "# print(len(lexicon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7219b26-28b2-483d-8034-1e162b4dfaa4",
   "metadata": {
    "id": "f7219b26-28b2-483d-8034-1e162b4dfaa4",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# chars_to_codes = {char:code for code, char in enumerate(lexicon)}\n",
    "# codes_to_chars = {code:char for char, code in chars_to_codes.items()}\n",
    "# output_path = '/content/drive/MyDrive/char_code_files/'\n",
    "\n",
    "# import json\n",
    "# import os\n",
    "# os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# # Save both JSON files\n",
    "# with open(output_path + 'chars_to_codes.json', 'w') as f:\n",
    "#     json.dump(chars_to_codes, f)\n",
    "\n",
    "# codes_to_chars_str_keys = {str(k): v for k, v in codes_to_chars.items()}\n",
    "# with open(output_path + 'codes_to_chars.json', 'w') as f:\n",
    "#     json.dump(codes_to_chars_str_keys, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52iqZ4B4jPSP",
   "metadata": {
    "id": "52iqZ4B4jPSP"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load chars_to_codes\n",
    "with open('/mnt/c/Users/abder/Documents/S8/DeepLearning/chars_to_codes.json', 'r') as f:\n",
    "    chars_to_codes = json.load(f)\n",
    "\n",
    "# Load codes_to_chars (JSON stores keys as strings, convert back to int)\n",
    "with open('/mnt/c/Users/abder/Documents/S8/DeepLearning/codes_to_chars.json', 'r') as f:\n",
    "    codes_to_chars = json.load(f)\n",
    "    codes_to_chars = {int(k): v for k, v in codes_to_chars.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "580b2e91-def7-4d69-bf07-0098b0ca329e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "580b2e91-def7-4d69-bf07-0098b0ca329e",
    "outputId": "d8f38ee8-bfce-47c0-c26e-aacd30ef8852"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'raA': 0, 'faA': 1, 'naA': 2, 'dhA': 3, 'daA': 4, 'toB': 5, 'waE': 6, '7A': 7, 'kaE': 8, 'thA': 9, 'maMlaB': 10, 'toM': 11, 'teE': 12, '9A': 13, 'aaA': 14, 'keE': 15, 'yaE': 16, 'taM': 17, 'deB': 18, 'waA': 19, 'shA': 20, 'baA': 21, 'baM': 22, 'aaElaB': 23, 'thM': 24, 'faB': 25, 'taB': 26, 'kaB': 27, 'saB': 28, 'thB': 29, 'kaM': 30, '0A': 31, 'haE': 32, 'naB': 33, 'eeA': 34, 'teA': 35, 'deE': 36, 'saE': 37, 'baE': 38, 'haB': 39, 'khMlaB': 40, 'jaB': 41, 'yaB': 42, 'shE': 43, 'jaMlaB': 44, 'toE': 45, 'jaM': 46, 'yaM': 47, 'laA': 48, 'shB': 49, 'keM': 50, 'dhE': 51, 'haA': 52, 'ayB': 53, 'shM': 54, 'zaB': 55, '2A': 56, 'laM': 57, 'faM': 58, 'maB': 59, 'khM': 60, 'ayA': 61, 'maE': 62, 'naE': 63, 'raE': 64, 'heE': 65, 'jaE': 66, 'keB': 67, 'aaElaM': 68, 'yaA': 69, 'haMmaMlaB': 70, 'baB': 71, 'seE': 72, 'maA': 73, 'naM': 74, 'amA': 75, 'ahElaB': 76, '8A': 77, 'khA': 78, 'taE': 79, 'laE': 80, 'heM': 81, '1A': 82, 'kaA': 83, 'haMlaB': 84, 'zaE': 85, 'seA': 86, 'maM': 87, 'laB': 88, 'seB': 89, 'ayE': 90, 'deA': 91, 'khE': 92, 'taA': 93, '6A': 94, 'haM': 95, 'saM': 96, 'ahA': 97, 'seM': 98, 'ghB': 99, 'eeE': 100, 'deM': 101, 'jaA': 102, 'daE': 103, 'aeElaB': 104, 'zaA': 105, 'zaM': 106, 'aaE': 107, 'alM': 108, 'heB': 109, 'faE': 110, 'khB': 111, 'heA': 112, 'aeA': 113, 'ayM': 114, 'saA': 115, 'toA': 116, 'ghM': 117, 'hhA': 118, '-': 119}\n"
     ]
    }
   ],
   "source": [
    "print(chars_to_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "abbe2d34-ecec-4920-9a49-f3524bb678d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'raA', 1: 'faA', 2: 'naA', 3: 'dhA', 4: 'daA', 5: 'toB', 6: 'waE', 7: '7A', 8: 'kaE', 9: 'thA', 10: 'maMlaB', 11: 'toM', 12: 'teE', 13: '9A', 14: 'aaA', 15: 'keE', 16: 'yaE', 17: 'taM', 18: 'deB', 19: 'waA', 20: 'shA', 21: 'baA', 22: 'baM', 23: 'aaElaB', 24: 'thM', 25: 'faB', 26: 'taB', 27: 'kaB', 28: 'saB', 29: 'thB', 30: 'kaM', 31: '0A', 32: 'haE', 33: 'naB', 34: 'eeA', 35: 'teA', 36: 'deE', 37: 'saE', 38: 'baE', 39: 'haB', 40: 'khMlaB', 41: 'jaB', 42: 'yaB', 43: 'shE', 44: 'jaMlaB', 45: 'toE', 46: 'jaM', 47: 'yaM', 48: 'laA', 49: 'shB', 50: 'keM', 51: 'dhE', 52: 'haA', 53: 'ayB', 54: 'shM', 55: 'zaB', 56: '2A', 57: 'laM', 58: 'faM', 59: 'maB', 60: 'khM', 61: 'ayA', 62: 'maE', 63: 'naE', 64: 'raE', 65: 'heE', 66: 'jaE', 67: 'keB', 68: 'aaElaM', 69: 'yaA', 70: 'haMmaMlaB', 71: 'baB', 72: 'seE', 73: 'maA', 74: 'naM', 75: 'amA', 76: 'ahElaB', 77: '8A', 78: 'khA', 79: 'taE', 80: 'laE', 81: 'heM', 82: '1A', 83: 'kaA', 84: 'haMlaB', 85: 'zaE', 86: 'seA', 87: 'maM', 88: 'laB', 89: 'seB', 90: 'ayE', 91: 'deA', 92: 'khE', 93: 'taA', 94: '6A', 95: 'haM', 96: 'saM', 97: 'ahA', 98: 'seM', 99: 'ghB', 100: 'eeE', 101: 'deM', 102: 'jaA', 103: 'daE', 104: 'aeElaB', 105: 'zaA', 106: 'zaM', 107: 'aaE', 108: 'alM', 109: 'heB', 110: 'faE', 111: 'khB', 112: 'heA', 113: 'aeA', 114: 'ayM', 115: 'saA', 116: 'toA', 117: 'ghM', 118: 'hhA', 119: '-'}\n"
     ]
    }
   ],
   "source": [
    "print(codes_to_chars )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04d3f872-335b-4df2-9bbe-bdc3c55bdde0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "04d3f872-335b-4df2-9bbe-bdc3c55bdde0",
    "outputId": "53648e21-9424-4da8-fc4d-02bb40d0d9c0"
   },
   "outputs": [],
   "source": [
    "# #get max length\n",
    "# lengths = get_lengths(names)\n",
    "# max_len = max(lengths.values())\n",
    "# print(max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9306345e-9222-420b-a478-d787d63b36a9",
   "metadata": {},
   "source": [
    "### Devide train and val and remove data augmented from val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ede7d8ea-7b49-4b01-ad53-7bc9e545e50b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ede7d8ea-7b49-4b01-ad53-7bc9e545e50b",
    "outputId": "455c8bd4-a196-4aeb-97bf-f4b959992ace"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import random\n",
    "# from collections import defaultdict\n",
    "\n",
    "# random.seed(42)\n",
    "\n",
    "# # Group images by base name (e.g., img1, img2, etc.)\n",
    "# grouped = defaultdict(list)\n",
    "\n",
    "# for name in names:\n",
    "#     # Extract the base name (before _aug or extension)\n",
    "#     base = os.path.basename(name).split('.')[0].split('_aug')[0]\n",
    "#     grouped[base].append(name)\n",
    "\n",
    "# # Convert the grouped values into a list of groups\n",
    "# groups = list(grouped.values())\n",
    "# random.shuffle(groups)\n",
    "\n",
    "# # Split groups into train and val\n",
    "# split_idx = int(len(groups) * 0.9)\n",
    "# train_groups = groups[:split_idx]\n",
    "# val_groups = groups[split_idx:]\n",
    "\n",
    "# # Flatten groups into lists of file paths\n",
    "# train = [item for group in train_groups for item in group]\n",
    "# val = [item for group in val_groups for item in group]\n",
    "\n",
    "# print(f'[INFO] {len(train)} train and {len(val)} validation images loaded')\n",
    "\n",
    "# # Save to disk\n",
    "# with open('/content/drive/MyDrive/train_names2.json', 'w') as f:\n",
    "#     json.dump(train, f)\n",
    "\n",
    "# with open('/content/drive/MyDrive/val_names2.json', 'w') as f:\n",
    "#     json.dump(val, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "Jsit4o9ncOxF",
   "metadata": {
    "id": "Jsit4o9ncOxF"
   },
   "outputs": [],
   "source": [
    "# Load train_data\n",
    "with open('/mnt/c/Users/abder/Downloads/train_names2.json', 'r') as f:\n",
    "    train = json.load(f)\n",
    "\n",
    "# Load val_data\n",
    "with open('/mnt/c/Users/abder/Downloads/val_names2.json', 'r') as f:\n",
    "    val = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "-Ls3NgnTVEVP",
   "metadata": {
    "id": "-Ls3NgnTVEVP"
   },
   "outputs": [],
   "source": [
    "# Remove only augmented images from the validation set\n",
    "val = [name for name in val if '_aug' not in os.path.basename(name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cWwCXYHKcgeM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cWwCXYHKcgeM",
    "outputId": "e9ecebc5-5fec-44d0-da45-c897cd2a2cf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 23301 train and 1044 validation images loaded\n"
     ]
    }
   ],
   "source": [
    "print(f'[INFO] {len(train)} train and {len(val)} validation images loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c8b7851-8e81-4a62-9aff-8f383f4d67ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_colab_to_wsl_paths(colab_paths):\n",
    "    wsl_base = \"/mnt/c/Users/abder/Documents/S8/DeepLearning/data_augmented/\"\n",
    "    wsl_paths = []\n",
    "\n",
    "    for path in colab_paths:\n",
    "        path = path.strip()\n",
    "        # Check for set_a, set_b, or set_c in path\n",
    "        if \"/set_a/\" in path:\n",
    "            idx = path.index(\"/set_a/\")\n",
    "            relative_path = path[idx+1:]  # remove leading slash before set_a\n",
    "            wsl_path = wsl_base + relative_path\n",
    "            wsl_paths.append(wsl_path)\n",
    "        elif \"/set_b/\" in path:\n",
    "            idx = path.index(\"/set_b/\")\n",
    "            relative_path = path[idx+1:]\n",
    "            wsl_path = wsl_base + relative_path\n",
    "            wsl_paths.append(wsl_path)\n",
    "        elif \"/set_c/\" in path:\n",
    "            idx = path.index(\"/set_c/\")\n",
    "            relative_path = path[idx+1:]\n",
    "            wsl_path = wsl_base + relative_path\n",
    "            wsl_paths.append(wsl_path)\n",
    "        else:\n",
    "            print(f\"[AVERTISSEMENT] Chemin ignoré : {path}\")\n",
    "\n",
    "    return wsl_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77e66ebd-b6d2-4e6e-9d6c-a9d7036043a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = convert_colab_to_wsl_paths(val)\n",
    "train = convert_colab_to_wsl_paths(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e6671d-32bb-4c2f-a4f1-84f451330e60",
   "metadata": {},
   "source": [
    "### Model architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca89943f-6e19-40d9-b5cb-05fc9d7d6e7c",
   "metadata": {
    "id": "ca89943f-6e19-40d9-b5cb-05fc9d7d6e7c"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Conv2D, BatchNormalization, LeakyReLU ,ReLU, DepthwiseConv2D, MaxPooling2D,\n",
    "                                     Dropout, ZeroPadding2D, Reshape, Dense, Lambda, Bidirectional, LSTM,\n",
    "                                     Attention, Add)\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "def ctc_loss(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    y_pred = y_pred[:, 2:, :]  # remove noisy initial steps\n",
    "    loss = K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def build_model(input_shape, num_classes, time_dense_size=128):\n",
    "    inputs = Input(name='the_input', shape=input_shape, dtype='float32')\n",
    "\n",
    "    # Convert grayscale (1 channel) to 3 channels by replicating\n",
    "    x = Concatenate(axis=-1)([inputs, inputs, inputs])  # (H, W, 3)\n",
    "\n",
    "    # Load ResNet50 without top layers\n",
    "    base_model = ResNet50(include_top=False, weights='imagenet', input_tensor=x)\n",
    "    x = base_model.output  # Feature map output: (None, H', W', C)\n",
    "\n",
    "    # Reshape to time steps for RNN\n",
    "    shape = x.shape  # (None, H', W', C)\n",
    "    x = Reshape((shape[1] * shape[2], shape[3]), name='reshape')(x)  # (time, features)\n",
    "\n",
    "    # Dense + Dropout\n",
    "    x = Dense(time_dense_size, activation='relu', name='dense1')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "\n",
    "    # BiLSTM\n",
    "    x = Bidirectional(LSTM(512, return_sequences=True), name='biLSTM_1')(x)\n",
    "    x = Bidirectional(LSTM(256, return_sequences=True), name='biLSTM_2')(x)\n",
    "\n",
    "    # Attention\n",
    "    attention_out = Attention()([x, x])\n",
    "    x = Concatenate(name='concat_attention')([x, attention_out])\n",
    "\n",
    "    # Output layer\n",
    "    y_pred = Dense(num_classes, activation='softmax', name='softmax')(x)\n",
    "\n",
    "    # CTC Loss setup\n",
    "    labels = Input(name='the_labels', shape=(17,), dtype='int32')\n",
    "    input_length = Input(name='input_length', shape=(1,), dtype='int32')\n",
    "    label_length = Input(name='label_length', shape=(1,), dtype='int32')\n",
    "\n",
    "    loss_out = Lambda(ctc_loss, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
    "\n",
    "    model = Model(inputs=[inputs, labels, input_length, label_length], outputs={'ctc': loss_out})\n",
    "    prediction_model = Model(inputs=inputs, outputs=y_pred)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a476dbf-aa3a-4cf2-81a6-50576b2c7d0e",
   "metadata": {},
   "source": [
    "### Function that prepares a single image-text pair "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "59629c59-68d1-41a3-84c5-dac47aa222ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_example(name, img_size, max_len, classes, downsample_factor):\n",
    "    img, word = get_image(name, img_size)\n",
    "    \n",
    "    if len(word) == 0:\n",
    "        return None\n",
    "\n",
    "    encoded = [classes.get(c, classes['-']) for c in word]\n",
    "    label_len = len(encoded)\n",
    "    \n",
    "    if label_len == 0:\n",
    "        return None\n",
    "\n",
    "    padded_label = np.full((max_len,), classes['-'], dtype=np.int32)\n",
    "    padded_label[:label_len] = encoded\n",
    "\n",
    "    img = img.astype(np.float32)\n",
    "    img = img[:, :, np.newaxis]\n",
    "\n",
    "    input_len = np.int32((img_size[1] + 4) // downsample_factor - 2)\n",
    "    label_len = np.int32(label_len)\n",
    "\n",
    "    return img, padded_label, input_len, label_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489af72d-5931-407f-89b6-521f2b2c13b1",
   "metadata": {},
   "source": [
    "### Creates a TensorFlow tf.data.Dataset pipeline for training or validating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4bfee061-c53c-4c73-868b-eeb833489290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def build_dataset(name_list, img_size, max_len, classes, batch_size, downsample_factor=8, shuffle=True):\n",
    "    # Wrap Python function\n",
    "    def wrapper(name):\n",
    "        result = tf.numpy_function(\n",
    "            func=lambda n: preprocess_example(\n",
    "                n.decode(\"utf-8\"), img_size, max_len, classes, downsample_factor),\n",
    "            inp=[name],\n",
    "            Tout=[tf.float32, tf.int32, tf.int32, tf.int32]\n",
    "        )\n",
    "        return {\n",
    "            \"the_input\": result[0],\n",
    "            \"the_labels\": result[1],\n",
    "            \"input_length\": tf.reshape(result[2], (1,)),\n",
    "            \"label_length\": tf.reshape(result[3], (1,))\n",
    "        }, {\n",
    "            \"ctc\": tf.zeros([1], dtype=tf.float32)\n",
    "        }\n",
    "\n",
    "    # Create Dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(name_list)\n",
    "\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=len(name_list))\n",
    "\n",
    "    dataset = dataset.map(wrapper, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.padded_batch(batch_size, padded_shapes=({\n",
    "        \"the_input\": (img_size[0], img_size[1], 1),\n",
    "        \"the_labels\": (max_len,),\n",
    "        \"input_length\": (1,),\n",
    "        \"label_length\": (1,)\n",
    "    }, {\n",
    "        \"ctc\": (batch_size,)\n",
    "    }), drop_remainder=True)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "162096f2-0e98-4ee1-a510-711ca23a78f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "class EpochCleanupCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "840d1196-c5e3-4da0-a639-71f120a815b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1750031236.415765    5992 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 0\n",
      "I0000 00:00:1750031236.416052    5992 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5520 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "input_shape = (100, 300, 1)\n",
    "num_classes = 120\n",
    "\n",
    "charset = [''] * len(chars_to_codes)\n",
    "for k, v in chars_to_codes.items():\n",
    "    charset[v] = k\n",
    "\n",
    "train_ds = build_dataset(train, img_size=(100, 300), max_len=17, classes=chars_to_codes, batch_size=64)\n",
    "val_ds = build_dataset(val, img_size=(100, 300), max_len=17, classes=chars_to_codes, batch_size=64, shuffle=False)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "## Build training model (with CTC loss inputs)\n",
    "model = build_model(input_shape, num_classes)\n",
    "\n",
    "# Create prediction model that takes only the images as input and outputs softmax predictions\n",
    "prediction_model = Model(inputs=model.input[0], outputs=model.get_layer('softmax').output)\n",
    "\n",
    "# Compile your training model\n",
    "optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, clipnorm=5)\n",
    "model.compile(\n",
    "    loss={'ctc': lambda y_true, y_pred: y_pred},\n",
    "    optimizer=optimizer\n",
    ")\n",
    "\n",
    "# Now pass prediction_model to your callback\n",
    "callbacks_list = [\n",
    "    ModelCheckpoint(\n",
    "        filepath='/mnt/c/Users/abder/Downloads/models_input_updated/checkpoint_model_OCR.keras',\n",
    "        verbose=1,\n",
    "        save_best_only=True\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=6,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    EpochCleanupCallback()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148a68a9-3c91-41bc-851b-351df4386b9c",
   "metadata": {},
   "source": [
    "### Training 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9a31a583-1534-4054-8237-6dd90e974908",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547ms/step - loss: 28.0710  \n",
      "Epoch 1: val_loss improved from inf to 63.26216, saving model to /mnt/c/Users/abder/Downloads/models_input_updated/checkpoint_model_OCR.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 573ms/step - loss: 28.0468 - val_loss: 63.2622 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562ms/step - loss: 7.1536  \n",
      "Epoch 2: val_loss improved from 63.26216 to 48.07472, saving model to /mnt/c/Users/abder/Downloads/models_input_updated/checkpoint_model_OCR.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 584ms/step - loss: 7.1504 - val_loss: 48.0747 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 3.1522     \n",
      "Epoch 3: val_loss improved from 48.07472 to 3.57116, saving model to /mnt/c/Users/abder/Downloads/models_input_updated/checkpoint_model_OCR.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m447s\u001b[0m 1s/step - loss: 3.1513 - val_loss: 3.5712 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - loss: 1.7752   \n",
      "Epoch 4: val_loss improved from 3.57116 to 2.43369, saving model to /mnt/c/Users/abder/Downloads/models_input_updated/checkpoint_model_OCR.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1699s\u001b[0m 5s/step - loss: 1.7749 - val_loss: 2.4337 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - loss: 1.1152   \n",
      "Epoch 5: val_loss improved from 2.43369 to 2.25151, saving model to /mnt/c/Users/abder/Downloads/models_input_updated/checkpoint_model_OCR.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2378s\u001b[0m 7s/step - loss: 1.1151 - val_loss: 2.2515 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - loss: 0.7638   \n",
      "Epoch 6: val_loss did not improve from 2.25151\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2261s\u001b[0m 6s/step - loss: 0.7641 - val_loss: 3.7384 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - loss: 1.2667   \n",
      "Epoch 7: val_loss improved from 2.25151 to 1.92941, saving model to /mnt/c/Users/abder/Downloads/models_input_updated/checkpoint_model_OCR.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2362s\u001b[0m 6s/step - loss: 1.2660 - val_loss: 1.9294 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - loss: 0.5165   \n",
      "Epoch 8: val_loss did not improve from 1.92941\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2355s\u001b[0m 6s/step - loss: 0.5165 - val_loss: 2.0169 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - loss: 0.4787   \n",
      "Epoch 9: val_loss did not improve from 1.92941\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2559s\u001b[0m 7s/step - loss: 0.4791 - val_loss: 2.7869 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - loss: 0.6845   \n",
      "Epoch 10: val_loss did not improve from 1.92941\n",
      "\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2478s\u001b[0m 7s/step - loss: 0.6843 - val_loss: 2.5571 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - loss: 0.2988   \n",
      "Epoch 11: val_loss improved from 1.92941 to 1.46276, saving model to /mnt/c/Users/abder/Downloads/models_input_updated/checkpoint_model_OCR.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2671s\u001b[0m 7s/step - loss: 0.2986 - val_loss: 1.4628 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - loss: 0.1226   \n",
      "Epoch 12: val_loss improved from 1.46276 to 1.40599, saving model to /mnt/c/Users/abder/Downloads/models_input_updated/checkpoint_model_OCR.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2738s\u001b[0m 8s/step - loss: 0.1225 - val_loss: 1.4060 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12s/step - loss: 0.0764     \n",
      "Epoch 13: val_loss improved from 1.40599 to 1.31533, saving model to /mnt/c/Users/abder/Downloads/models_input_updated/checkpoint_model_OCR.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4290s\u001b[0m 12s/step - loss: 0.0763 - val_loss: 1.3153 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - loss: 0.0469   \n",
      "Epoch 14: val_loss did not improve from 1.31533\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2764s\u001b[0m 8s/step - loss: 0.0469 - val_loss: 1.3360 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - loss: 0.0548   \n",
      "Epoch 15: val_loss did not improve from 1.31533\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3060s\u001b[0m 8s/step - loss: 0.0548 - val_loss: 1.5167 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - loss: 0.0565    \n",
      "Epoch 16: val_loss did not improve from 1.31533\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3171s\u001b[0m 9s/step - loss: 0.0565 - val_loss: 1.4422 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m146/364\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m32:15\u001b[0m 9s/step - loss: 0.0383"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-15 04:19:36.618897: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:359] gpu_async_0 cuMemAllocAsync failed to allocate 53674752 bytes: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      " Reported by CUDA: Free memory/Total memory: 0/8585216000\n",
      "2025-06-15 04:19:36.620385: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:364] Stats: Limit:                      5788139520\n",
      "InUse:                      4259308585\n",
      "MaxInUse:                   5058414561\n",
      "NumAllocs:                    29516303\n",
      "MaxAllocSize:               1462763536\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2025-06-15 04:19:36.620662: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:68] Histogram of current allocation: (allocation_size_in_bytes, nb_allocation_of_that_sizes), ...;\n",
      "2025-06-15 04:19:36.620667: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 1, 1\n",
      "2025-06-15 04:19:36.620669: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 4, 6731\n",
      "2025-06-15 04:19:36.620670: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 8, 25\n",
      "2025-06-15 04:19:36.620671: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 16, 11\n",
      "2025-06-15 04:19:36.620672: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 24, 4\n",
      "2025-06-15 04:19:36.620673: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 256, 178\n",
      "2025-06-15 04:19:36.620674: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 480, 7\n",
      "2025-06-15 04:19:36.620675: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 512, 206\n",
      "2025-06-15 04:19:36.620675: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 1024, 400\n",
      "2025-06-15 04:19:36.620676: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 1028, 1\n",
      "2025-06-15 04:19:36.620677: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 2048, 275\n",
      "2025-06-15 04:19:36.620678: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 4096, 189\n",
      "2025-06-15 04:19:36.620679: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 8192, 114\n",
      "2025-06-15 04:19:36.620679: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 16384, 6\n",
      "2025-06-15 04:19:36.620680: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 37632, 6\n",
      "2025-06-15 04:19:36.620681: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 65536, 44\n",
      "2025-06-15 04:19:36.620682: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 131072, 12\n",
      "2025-06-15 04:19:36.620682: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 147456, 18\n",
      "2025-06-15 04:19:36.620683: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 262144, 42\n",
      "2025-06-15 04:19:36.620684: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 327680, 1\n",
      "2025-06-15 04:19:36.620685: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 491520, 8\n",
      "2025-06-15 04:19:36.620685: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 524288, 12\n",
      "2025-06-15 04:19:36.620686: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 589824, 24\n",
      "2025-06-15 04:19:36.620687: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 1048576, 96\n",
      "2025-06-15 04:19:36.620688: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 1310720, 3\n",
      "2025-06-15 04:19:36.620688: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 2097152, 12\n",
      "2025-06-15 04:19:36.620689: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 2359296, 36\n",
      "2025-06-15 04:19:36.620690: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 2621440, 4\n",
      "2025-06-15 04:19:36.620691: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 4194304, 54\n",
      "2025-06-15 04:19:36.620693: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 5242880, 14\n",
      "2025-06-15 04:19:36.620694: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 5251072, 3\n",
      "2025-06-15 04:19:36.620695: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 5259264, 2\n",
      "2025-06-15 04:19:36.620696: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 8388608, 6\n",
      "2025-06-15 04:19:36.620696: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 8716288, 24\n",
      "2025-06-15 04:19:36.620697: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 9437184, 18\n",
      "2025-06-15 04:19:36.620698: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 10485760, 3\n",
      "2025-06-15 04:19:36.620699: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 13107456, 2\n",
      "2025-06-15 04:19:36.620700: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 16187392, 16\n",
      "2025-06-15 04:19:36.620700: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 20971520, 8\n",
      "2025-06-15 04:19:36.620701: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 24910848, 1\n",
      "2025-06-15 04:19:36.620702: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 26214656, 2\n",
      "2025-06-15 04:19:36.620703: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 30720000, 13\n",
      "2025-06-15 04:19:36.620703: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 34865152, 13\n",
      "2025-06-15 04:19:36.620704: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 64749568, 9\n",
      "2025-06-15 04:19:36.620705: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 122880000, 9\n",
      "2025-06-15 04:19:36.620706: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 129499136, 1\n",
      "2025-06-15 04:19:36.621096: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:104] CU_MEMPOOL_ATTR_RESERVED_MEM_CURRENT: 17146314752\n",
      "2025-06-15 04:19:36.621105: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:106] CU_MEMPOOL_ATTR_USED_MEM_CURRENT: 4259308585\n",
      "2025-06-15 04:19:36.621106: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:107] CU_MEMPOOL_ATTR_RESERVED_MEM_HIGH: 17179869184\n",
      "2025-06-15 04:19:36.621108: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:108] CU_MEMPOOL_ATTR_USED_MEM_HIGH: 5058414561\n",
      "E0000 00:00:1749957576.621587    1420 dnn.cc:948] OOM when allocating tensor with shape[53674752] and type uint8 on /job:localhost/replica:0/task:0/device:GPU:0 by allocator gpu_async_0\n",
      "2025-06-15 04:19:36.623124: W tensorflow/core/framework/op_kernel.cc:1857] OP_REQUIRES failed at cudnn_rnn_ops.cc:2182 : INTERNAL: Failed to call DoRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 1024, 256, 1, 40, 64, 256] \n",
      "2025-06-15 04:19:36.623201: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: INTERNAL: Failed to call DoRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 1024, 256, 1, 40, 64, 256] \n",
      "\t [[{{function_node __inference_one_step_on_data_119173}}{{node gradient_tape/functional_1/biLSTM_2_1/forward_lstm_1_1/CudnnRNNBackpropV3}}]]\n",
      "2025-06-15 04:19:36.629964: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:359] gpu_async_0 cuMemAllocAsync failed to allocate 53674752 bytes: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      " Reported by CUDA: Free memory/Total memory: 0/8585216000\n",
      "2025-06-15 04:19:36.629985: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:364] Stats: Limit:                      5788139520\n",
      "InUse:                      4224107781\n",
      "MaxInUse:                   5058414561\n",
      "NumAllocs:                    29516312\n",
      "MaxAllocSize:               1462763536\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2025-06-15 04:19:36.630095: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:68] Histogram of current allocation: (allocation_size_in_bytes, nb_allocation_of_that_sizes), ...;\n",
      "2025-06-15 04:19:36.630106: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 1, 1\n",
      "2025-06-15 04:19:36.630108: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 4, 6730\n",
      "2025-06-15 04:19:36.630109: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 8, 25\n",
      "2025-06-15 04:19:36.630110: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 16, 11\n",
      "2025-06-15 04:19:36.630111: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 24, 4\n",
      "2025-06-15 04:19:36.630112: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 256, 178\n",
      "2025-06-15 04:19:36.630113: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 480, 8\n",
      "2025-06-15 04:19:36.630114: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 512, 206\n",
      "2025-06-15 04:19:36.630115: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 1024, 400\n",
      "2025-06-15 04:19:36.630115: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 1028, 1\n",
      "2025-06-15 04:19:36.630116: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 2048, 275\n",
      "2025-06-15 04:19:36.630117: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 4096, 189\n",
      "2025-06-15 04:19:36.630118: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 8192, 114\n",
      "2025-06-15 04:19:36.630119: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 16384, 6\n",
      "2025-06-15 04:19:36.630119: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 37632, 6\n",
      "2025-06-15 04:19:36.630120: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 65536, 42\n",
      "2025-06-15 04:19:36.630121: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 131072, 12\n",
      "2025-06-15 04:19:36.630122: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 147456, 18\n",
      "2025-06-15 04:19:36.630123: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 262144, 42\n",
      "2025-06-15 04:19:36.630123: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 327680, 1\n",
      "2025-06-15 04:19:36.630124: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 491520, 6\n",
      "2025-06-15 04:19:36.630125: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 524288, 12\n",
      "2025-06-15 04:19:36.630126: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 589824, 24\n",
      "2025-06-15 04:19:36.630126: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 1048576, 96\n",
      "2025-06-15 04:19:36.630127: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 1310720, 3\n",
      "2025-06-15 04:19:36.630128: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 2097152, 12\n",
      "2025-06-15 04:19:36.630129: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 2359296, 36\n",
      "2025-06-15 04:19:36.630129: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 2621440, 2\n",
      "2025-06-15 04:19:36.630130: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 4194304, 54\n",
      "2025-06-15 04:19:36.630131: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 5242880, 14\n",
      "2025-06-15 04:19:36.630132: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 5251072, 2\n",
      "2025-06-15 04:19:36.630132: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 5259264, 2\n",
      "2025-06-15 04:19:36.630133: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 8388608, 6\n",
      "2025-06-15 04:19:36.630134: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 8716288, 24\n",
      "2025-06-15 04:19:36.630134: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 9437184, 18\n",
      "2025-06-15 04:19:36.630135: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 10485760, 2\n",
      "2025-06-15 04:19:36.630136: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 13107456, 1\n",
      "2025-06-15 04:19:36.630137: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 16187392, 16\n",
      "2025-06-15 04:19:36.630139: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 20971520, 8\n",
      "2025-06-15 04:19:36.630140: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 24910848, 1\n",
      "2025-06-15 04:19:36.630141: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 26214656, 2\n",
      "2025-06-15 04:19:36.630141: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 30720000, 13\n",
      "2025-06-15 04:19:36.630142: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 34865152, 13\n",
      "2025-06-15 04:19:36.630143: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 64749568, 9\n",
      "2025-06-15 04:19:36.630144: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 122880000, 9\n",
      "2025-06-15 04:19:36.630144: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 129499136, 1\n",
      "2025-06-15 04:19:36.630147: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:104] CU_MEMPOOL_ATTR_RESERVED_MEM_CURRENT: 17146314752\n",
      "2025-06-15 04:19:36.630148: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:106] CU_MEMPOOL_ATTR_USED_MEM_CURRENT: 4224107781\n",
      "2025-06-15 04:19:36.630150: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:107] CU_MEMPOOL_ATTR_RESERVED_MEM_HIGH: 17179869184\n",
      "2025-06-15 04:19:36.630151: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:108] CU_MEMPOOL_ATTR_USED_MEM_HIGH: 5058414561\n",
      "E0000 00:00:1749957576.630157    1420 dnn.cc:948] OOM when allocating tensor with shape[53674752] and type uint8 on /job:localhost/replica:0/task:0/device:GPU:0 by allocator gpu_async_0\n",
      "2025-06-15 04:19:36.630175: W tensorflow/core/framework/op_kernel.cc:1857] OP_REQUIRES failed at cudnn_rnn_ops.cc:2182 : INTERNAL: Failed to call DoRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 1024, 256, 1, 40, 64, 256] \n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Graph execution error:\n\nDetected at node gradient_tape/functional_1/biLSTM_2_1/forward_lstm_1_1/CudnnRNNBackpropV3 defined at (most recent call last):\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 211, in start\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_1330/2101959980.py\", line 1, in <module>\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 377, in fit\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 133, in multi_step_on_iterator\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 114, in one_step_on_data\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 78, in train_step\n\nFailed to call DoRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 1024, 256, 1, 40, 64, 256] \n\t [[{{node gradient_tape/functional_1/biLSTM_2_1/forward_lstm_1_1/CudnnRNNBackpropV3}}]] [Op:__inference_multi_step_on_iterator_120767]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_list\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/env_name/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/env_name/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInternalError\u001b[0m: Graph execution error:\n\nDetected at node gradient_tape/functional_1/biLSTM_2_1/forward_lstm_1_1/CudnnRNNBackpropV3 defined at (most recent call last):\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 211, in start\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_1330/2101959980.py\", line 1, in <module>\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 377, in fit\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 133, in multi_step_on_iterator\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 114, in one_step_on_data\n\n  File \"/home/abder/miniconda3/envs/env_name/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 78, in train_step\n\nFailed to call DoRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 1024, 256, 1, 40, 64, 256] \n\t [[{{node gradient_tape/functional_1/biLSTM_2_1/forward_lstm_1_1/CudnnRNNBackpropV3}}]] [Op:__inference_multi_step_on_iterator_120767]"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=50,\n",
    "    callbacks=callbacks_list\n",
    ")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a8aea1-13b3-4a16-8950-df159c068a86",
   "metadata": {},
   "source": [
    "### Training 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "667ef6f4-19fe-4e7a-ba16-4ac1d55d976d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.saving import register_keras_serializable\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Register CTC loss for deserialization\n",
    "@register_keras_serializable()\n",
    "def ctc_loss(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "# Load full model\n",
    "model = load_model(\n",
    "    '/mnt/c/Users/abder/Downloads/models_input_updated/Resnet2LSTMFinal(76).keras',\n",
    "    custom_objects={'ctc_loss': ctc_loss},\n",
    "    compile=False\n",
    ")\n",
    "\n",
    "# Freeze all layers first\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Unfreeze only the last 30 layers\n",
    "for layer in model.layers[-30:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Compile model\n",
    "optimizer = Adam(learning_rate=1e-4, beta_1=0.9, beta_2=0.999, clipnorm=5)\n",
    "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=optimizer)\n",
    "\n",
    "# Set up callback\n",
    "callbacks_list = [\n",
    "    ModelCheckpoint(\n",
    "        filepath='/mnt/c/Users/abder/Downloads/models_input_updated/checkpoint_model_OCR.keras',\n",
    "        verbose=1,\n",
    "        save_best_only=True\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=6,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    EpochCleanupCallback()\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "796519db-f222-48ff-8319-11be27b6309d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1750021898.657289     523 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - loss: 0.0462  \n",
      "Epoch 17: val_loss improved from inf to 1.30361, saving model to /mnt/c/Users/abder/Downloads/models_input_updated/checkpoint_model_OCR.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 325ms/step - loss: 0.0462 - val_loss: 1.3036 - learning_rate: 1.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0291  \n",
      "Epoch 18: val_loss did not improve from 1.30361\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 192ms/step - loss: 0.0292 - val_loss: 1.3398 - learning_rate: 1.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0247  \n",
      "Epoch 19: val_loss did not improve from 1.30361\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 201ms/step - loss: 0.0247 - val_loss: 1.3464 - learning_rate: 1.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.0211 \n",
      "Epoch 20: val_loss did not improve from 1.30361\n",
      "\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 219ms/step - loss: 0.0211 - val_loss: 1.3470 - learning_rate: 1.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: 0.0152  \n",
      "Epoch 21: val_loss did not improve from 1.30361\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 229ms/step - loss: 0.0152 - val_loss: 1.3547 - learning_rate: 5.0000e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0141  \n",
      "Epoch 22: val_loss did not improve from 1.30361\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 199ms/step - loss: 0.0141 - val_loss: 1.3612 - learning_rate: 5.0000e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0127  \n",
      "Epoch 23: val_loss did not improve from 1.30361\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 205ms/step - loss: 0.0127 - val_loss: 1.3574 - learning_rate: 5.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f97141a3c70>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resume training from epoch 16\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=50,\n",
    "    initial_epoch=16,\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "702fa6a7-f269-48c5-bbc5-e53eb4193e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.saving import register_keras_serializable\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Register CTC loss for deserialization\n",
    "@register_keras_serializable()\n",
    "def ctc_loss(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "# Load full model\n",
    "model = load_model(\n",
    "    '/mnt/c/Users/abder/Downloads/models_input_updated/Resnet2LSTMFinal(76).keras',\n",
    "    custom_objects={'ctc_loss': ctc_loss},\n",
    "    compile=False\n",
    ")\n",
    "\n",
    "# Freeze all layers first\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Unfreeze only the last 30 layers\n",
    "for layer in model.layers[-50:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Compile model (you already correctly used dummy loss for Lambda)\n",
    "optimizer = Adam(learning_rate=1e-5, beta_1=0.9, beta_2=0.999, clipnorm=5)\n",
    "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=optimizer)\n",
    "\n",
    "# Set up callbacks (assuming EpochCleanupCallback is defined somewhere)\n",
    "callbacks_list = [\n",
    "    ModelCheckpoint(\n",
    "        filepath='/mnt/c/Users/abder/Downloads/models_input_updated/checkpoint_model_OCR.keras',\n",
    "        verbose=1,\n",
    "        save_best_only=True\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=6,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    EpochCleanupCallback()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5cd64973-8a0a-463f-aafb-fd5210e3b0b5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - loss: 0.0529  \n",
      "Epoch 17: val_loss improved from inf to 1.30553, saving model to /mnt/c/Users/abder/Downloads/models_input_updated/checkpoint_model_OCR.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 243ms/step - loss: 0.0529 - val_loss: 1.3055 - learning_rate: 1.0000e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - loss: 0.0426  \n",
      "Epoch 18: val_loss improved from 1.30553 to 1.29965, saving model to /mnt/c/Users/abder/Downloads/models_input_updated/checkpoint_model_OCR.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 233ms/step - loss: 0.0426 - val_loss: 1.2996 - learning_rate: 1.0000e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - loss: 0.0367  \n",
      "Epoch 19: val_loss improved from 1.29965 to 1.29346, saving model to /mnt/c/Users/abder/Downloads/models_input_updated/checkpoint_model_OCR.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 243ms/step - loss: 0.0367 - val_loss: 1.2935 - learning_rate: 1.0000e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - loss: 0.0325  \n",
      "Epoch 20: val_loss did not improve from 1.29346\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 232ms/step - loss: 0.0325 - val_loss: 1.2941 - learning_rate: 1.0000e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 0.0293      \n",
      "Epoch 21: val_loss improved from 1.29346 to 1.29072, saving model to /mnt/c/Users/abder/Downloads/models_input_updated/checkpoint_model_OCR.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m397s\u001b[0m 1s/step - loss: 0.0293 - val_loss: 1.2907 - learning_rate: 1.0000e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 0.0288   \n",
      "Epoch 22: val_loss did not improve from 1.29072\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 1s/step - loss: 0.0288 - val_loss: 1.2919 - learning_rate: 1.0000e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 0.0288     \n",
      "Epoch 23: val_loss did not improve from 1.29072\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m475s\u001b[0m 1s/step - loss: 0.0288 - val_loss: 1.2972 - learning_rate: 1.0000e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 0.0267     \n",
      "Epoch 24: val_loss improved from 1.29072 to 1.28923, saving model to /mnt/c/Users/abder/Downloads/models_input_updated/checkpoint_model_OCR.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 1s/step - loss: 0.0267 - val_loss: 1.2892 - learning_rate: 1.0000e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 0.0255   \n",
      "Epoch 25: val_loss did not improve from 1.28923\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m476s\u001b[0m 1s/step - loss: 0.0255 - val_loss: 1.2990 - learning_rate: 1.0000e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 0.0254   \n",
      "Epoch 26: val_loss did not improve from 1.28923\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m559s\u001b[0m 2s/step - loss: 0.0254 - val_loss: 1.2932 - learning_rate: 1.0000e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m 67/364\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:01\u001b[0m 1s/step - loss: 0.0216   "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Resume training from epoch 16\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_list\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/env_name/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/env_name/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:377\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    376\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 377\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/miniconda3/envs/env_name/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:220\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    218\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    219\u001b[0m     ):\n\u001b[0;32m--> 220\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    222\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/env_name/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/env_name/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/env_name/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/env_name/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/env_name/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/env_name/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/env_name/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/env_name/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1691\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1692\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1693\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1694\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1703\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/envs/env_name/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Resume training from epoch 16\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=50,\n",
    "    initial_epoch=16,\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ec6eda0-3029-477b-bf46-ebdb177aeade",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.saving import register_keras_serializable\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Register CTC loss for deserialization\n",
    "@register_keras_serializable()\n",
    "def ctc_loss(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "# Load full model\n",
    "model = load_model(\n",
    "    '/mnt/c/Users/abder/Downloads/models_input_updated/checkpoint_model_OCR.keras',\n",
    "    custom_objects={'ctc_loss': ctc_loss},\n",
    "    compile=False\n",
    ")\n",
    "\n",
    "\n",
    "# Freeze all layers first\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "    \n",
    "# Compile model (you already correctly used dummy loss for Lambda)\n",
    "optimizer = Adam(learning_rate=1e-5, beta_1=0.9, beta_2=0.999, clipnorm=5)\n",
    "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=optimizer)\n",
    "\n",
    "# Set up callbacks (assuming EpochCleanupCallback is defined somewhere)\n",
    "callbacks_list = [\n",
    "    ModelCheckpoint(\n",
    "        filepath='/mnt/c/Users/abder/Downloads/models_input_updated/checkpoint_model_OCR_continue.keras',\n",
    "        verbose=1,\n",
    "        save_best_only=True\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=6,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    EpochCleanupCallback()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b76c3e8-ba45-4d0c-8c5a-f293b10a86f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519ms/step - loss: 0.0263  \n",
      "Epoch 27: val_loss improved from inf to 1.28345, saving model to /mnt/c/Users/abder/Downloads/models_input_updated/checkpoint_model_OCR_continue.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 545ms/step - loss: 0.0263 - val_loss: 1.2834 - learning_rate: 1.0000e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527ms/step - loss: 0.0241  \n",
      "Epoch 28: val_loss improved from 1.28345 to 1.27864, saving model to /mnt/c/Users/abder/Downloads/models_input_updated/checkpoint_model_OCR_continue.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 549ms/step - loss: 0.0241 - val_loss: 1.2786 - learning_rate: 1.0000e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538ms/step - loss: 0.0239  \n",
      "Epoch 29: val_loss did not improve from 1.27864\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 548ms/step - loss: 0.0239 - val_loss: 1.2847 - learning_rate: 1.0000e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536ms/step - loss: 0.0216  \n",
      "Epoch 30: val_loss did not improve from 1.27864\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 546ms/step - loss: 0.0216 - val_loss: 1.2923 - learning_rate: 1.0000e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543ms/step - loss: 0.0218  \n",
      "Epoch 31: val_loss did not improve from 1.27864\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 552ms/step - loss: 0.0218 - val_loss: 1.2957 - learning_rate: 1.0000e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537ms/step - loss: 0.0203  \n",
      "Epoch 32: val_loss did not improve from 1.27864\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 553ms/step - loss: 0.0203 - val_loss: 1.2939 - learning_rate: 5.0000e-06\n",
      "Epoch 33/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546ms/step - loss: 0.0199  \n",
      "Epoch 33: val_loss did not improve from 1.27864\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 556ms/step - loss: 0.0199 - val_loss: 1.2925 - learning_rate: 5.0000e-06\n",
      "Epoch 34/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549ms/step - loss: 0.0175  \n",
      "Epoch 34: val_loss did not improve from 1.27864\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 559ms/step - loss: 0.0175 - val_loss: 1.2996 - learning_rate: 5.0000e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fcc466e74f0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resume training from epoch 16\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=50,\n",
    "    initial_epoch=26,\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3711bc92-9ed2-44bb-a7d9-d7de413304b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.saving import register_keras_serializable\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Register CTC loss for deserialization\n",
    "@register_keras_serializable()\n",
    "def ctc_loss(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "# Load full model\n",
    "model = load_model(\n",
    "    '/mnt/c/Users/abder/Downloads/models_input_updated/checkpoint_model_OCR_continue.keras',\n",
    "    custom_objects={'ctc_loss': ctc_loss},\n",
    "    compile=False\n",
    ")\n",
    "\n",
    "\n",
    "# Freeze all layers first\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "    \n",
    "# Compile model (you already correctly used dummy loss for Lambda)\n",
    "optimizer = Adam(learning_rate=1e-6, beta_1=0.9, beta_2=0.999, clipnorm=5)\n",
    "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=optimizer)\n",
    "\n",
    "# Set up callbacks (assuming EpochCleanupCallback is defined somewhere)\n",
    "callbacks_list = [\n",
    "    ModelCheckpoint(\n",
    "        filepath='/mnt/c/Users/abder/Downloads/models_input_updated/checkpoint_model_OCR_continue_cont.keras',\n",
    "        verbose=1,\n",
    "        save_best_only=True\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-8,\n",
    "        verbose=1\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=7,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    EpochCleanupCallback()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b7fdeab5-2894-4fcf-9594-5d0c21b5e12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1750031281.230440    6104 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553ms/step - loss: 0.0236  \n",
      "Epoch 27: val_loss improved from inf to 1.27720, saving model to /mnt/c/Users/abder/Downloads/models_input_updated/checkpoint_model_OCR_continue_cont.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 580ms/step - loss: 0.0236 - val_loss: 1.2772 - learning_rate: 1.0000e-06\n",
      "Epoch 28/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568ms/step - loss: 0.0209  \n",
      "Epoch 28: val_loss did not improve from 1.27720\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 576ms/step - loss: 0.0209 - val_loss: 1.2785 - learning_rate: 1.0000e-06\n",
      "Epoch 29/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585ms/step - loss: 0.0238  \n",
      "Epoch 29: val_loss did not improve from 1.27720\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 595ms/step - loss: 0.0238 - val_loss: 1.2792 - learning_rate: 1.0000e-06\n",
      "Epoch 30/50\n",
      "\u001b[1m337/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m20s\u001b[0m 768ms/step - loss: 0.0214 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Resume training from epoch 16\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m26\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_list\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/env_name/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/env_name/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:377\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    376\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 377\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/miniconda3/envs/env_name/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:220\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    218\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    219\u001b[0m     ):\n\u001b[0;32m--> 220\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    222\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/env_name/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/env_name/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/env_name/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/env_name/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/env_name/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/env_name/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/env_name/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/env_name/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1691\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1692\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1693\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1694\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1703\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/envs/env_name/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Resume training from epoch 16\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=50,\n",
    "    initial_epoch=26,\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1692dde0-f373-4292-9987-84740979036c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Données epochs 1 à 16\n",
    "losses_1_16 = [28.07, 7.15, 3.15, 1.77, 1.11, 0.76, 1.27, 0.52, 0.48, 0.68, 0.30, 0.12, 0.08, 0.05, 0.05, 0.06]\n",
    "val_losses_1_16 = [63.26, 48.07, 3.57, 2.43, 2.25, 3.74, 1.93, 2.02, 2.79, 2.56, 1.46, 1.41, 1.31, 1.34, 1.52, 1.44]\n",
    "epochs_1_16 = list(range(1, len(losses_1_16) + 1))\n",
    "\n",
    "# Données epochs 17 à 26\n",
    "losses_17_26 = [0.0529, 0.0426, 0.0367, 0.0325, 0.0293, 0.0288, 0.0288, 0.0267, 0.0255, 0.0254]\n",
    "val_losses_17_26 = [1.3055, 1.2996, 1.2935, 1.2941, 1.2907, 1.2919, 1.2972, 1.2892, 1.2990, 1.2932]\n",
    "epochs_17_26 = list(range(17, 27))\n",
    "\n",
    "# Données epochs 27 à 34\n",
    "losses_27_34 = [0.0263, 0.0241, 0.0239, 0.0216, 0.0218, 0.0203, 0.0199, 0.0175]\n",
    "val_losses_27_34 = [1.2834, 1.2786, 1.2847, 1.2923, 1.2957, 1.2939, 1.2925, 1.2996]\n",
    "epochs_27_34 = list(range(27, 35))\n",
    "\n",
    "# Fusionner toutes les listes pour courbe continue\n",
    "losses = losses_1_16 + losses_17_26 + losses_27_34\n",
    "val_losses = val_losses_1_16 + val_losses_17_26 + val_losses_27_34\n",
    "epochs = epochs_1_16 + epochs_17_26 + epochs_27_34\n",
    "\n",
    "plt.figure(figsize=(12,7))\n",
    "\n",
    "plt.plot(epochs, losses, 'b-o', label='Training Loss')\n",
    "plt.plot(epochs, val_losses, 'r-o', label='Validation Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss over Epochs 1 to 34')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
